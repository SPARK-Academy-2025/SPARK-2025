{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T06:56:31.705023Z",
     "iopub.status.busy": "2025-07-12T06:56:31.704328Z",
     "iopub.status.idle": "2025-07-12T06:56:31.709384Z",
     "shell.execute_reply": "2025-07-12T06:56:31.708556Z",
     "shell.execute_reply.started": "2025-07-12T06:56:31.704988Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#pip install connected-components-3d monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-12T06:56:31.717074Z",
     "iopub.status.busy": "2025-07-12T06:56:31.716855Z",
     "iopub.status.idle": "2025-07-12T06:56:31.737952Z",
     "shell.execute_reply": "2025-07-12T06:56:31.737169Z",
     "shell.execute_reply.started": "2025-07-12T06:56:31.717057Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"This module contains functions for preprocessing MRI images and segmentations.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "\n",
    "def znorm_rescale(img):\n",
    "    \"\"\"Applies Z-score normalization and rescaling to a MRI image.\"\"\"\n",
    "\n",
    "    # Z-score norm\n",
    "    movingNan=np.copy(img)\n",
    "    movingNan[movingNan==0]=np.nan\n",
    "    movingMean=np.nanmean(movingNan)\n",
    "    movingSTD=np.nanstd(movingNan)\n",
    "    moving=(img-movingMean)/movingSTD\n",
    "    b=255/(1-(moving.max()/moving.min()))\n",
    "    a=-b/moving.min()\n",
    "    movingNorm=np.copy(moving)\n",
    "    movingNorm=np.round((movingNorm*a)+b,2)\n",
    "\n",
    "    # Rescaling\n",
    "    p2, p98 = np.percentile(movingNorm, (1, 99)) # These parameters may not be optimal, further testing could be done\n",
    "    moving_rescale = exposure.rescale_intensity(movingNorm, in_range=(p2, p98))\n",
    "\n",
    "    return moving_rescale\n",
    "\n",
    "# Crop ranges for center crop.\n",
    "X_START, X_END, Y_START, Y_END, Z_START, Z_END = (56,184, 24,216, 14,142)\n",
    "\n",
    "def center_crop(img):\n",
    "    \"\"\"Center crops a MRI image (or seg) to be (128, 192, 128).\"\"\"\n",
    "    return img[X_START:X_END, Y_START:Y_END, Z_START:Z_END]\n",
    "\n",
    "def undo_center_crop(input):\n",
    "    \"\"\"Undos center crop of a MRI image (or seg).\"\"\"\n",
    "    out = np.zeros((240, 240, 155))\n",
    "    out[X_START:X_END, Y_START:Y_END, Z_START:Z_END] = input \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "postprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T12:27:58.164423Z",
     "iopub.status.busy": "2025-07-12T12:27:58.163901Z",
     "iopub.status.idle": "2025-07-12T12:27:58.176975Z",
     "shell.execute_reply": "2025-07-12T12:27:58.176087Z",
     "shell.execute_reply.started": "2025-07-12T12:27:58.164399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Enhanced postprocessing module with adaptive thresholds and morphology-aware processing\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cc3d\n",
    "from skimage.morphology import dilation, ball\n",
    "\n",
    "def adaptive_rm_dust(pred_mat):\n",
    "    \"\"\"Enhanced dust removal with adaptive thresholds and morphology preservation\"\"\"\n",
    "    # Initial conservative pass to preserve small structures\n",
    "    pred_mat_clean = cc3d.dust(pred_mat, threshold=70, connectivity=26)\n",
    "    \n",
    "    # Secondary pass with label-specific processing\n",
    "    for label in [1, 2, 3]:  # Process each label separately\n",
    "        if label in pred_mat_clean:\n",
    "            label_mask = (pred_mat_clean == label)\n",
    "            \n",
    "            # Label-specific thresholds\n",
    "            thresholds = {1: 35, 2: 60, 3: 30}  # TC, WT, ET respectively\n",
    "            structure = ball(1) if label == 3 else ball(2)  # Smaller for ET\n",
    "            \n",
    "            # Morphological closing to preserve structure\n",
    "            label_mask = dilation(label_mask, structure)\n",
    "            cleaned = cc3d.dust(label_mask, threshold=thresholds[label], connectivity=26)\n",
    "            pred_mat_clean[np.logical_and(pred_mat_clean == label, ~cleaned)] = 0\n",
    "    \n",
    "    return pred_mat_clean\n",
    "\n",
    "def get_tissue_wise_seg(pred_mat, tissue_type, dilation_size=0):\n",
    "    \"\"\"Enhanced with optional morphological dilation to bridge small gaps\"\"\"\n",
    "    mask = np.zeros_like(pred_mat)\n",
    "    \n",
    "    if tissue_type == 'WT':\n",
    "        mask = pred_mat > 0\n",
    "    elif tissue_type == 'TC':\n",
    "        mask = np.logical_or(pred_mat == 1, pred_mat == 3)\n",
    "    elif tissue_type == 'ET':\n",
    "        mask = pred_mat == 3\n",
    "    \n",
    "    if dilation_size > 0:\n",
    "        mask = dilation(mask, ball(dilation_size))\n",
    "    \n",
    "    return mask.astype(np.uint16)\n",
    "\n",
    "def enhanced_rm_tt_dust(pred_mat, tt):\n",
    "    \"\"\"Enhanced dust removal with adaptive morphology\"\"\"\n",
    "    # Strategy parameters\n",
    "    strategies = {\n",
    "        'ET': {\n",
    "            'threshold': 10,  # Very sensitive for ET\n",
    "            'connectivity': 6,\n",
    "            'dilation': 1,   # Small dilation to bridge gaps\n",
    "            'min_volume': 10 # Minimum volume to preserve\n",
    "        },\n",
    "        'TC': {\n",
    "            'threshold': 40,\n",
    "            'connectivity': 18,\n",
    "            'dilation': 0,\n",
    "            'min_volume': 20\n",
    "        },\n",
    "        'WT': {\n",
    "            'threshold': 60,\n",
    "            'connectivity': 26,\n",
    "            'dilation': 0,\n",
    "            'min_volume': 30\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    params = strategies[tt]\n",
    "    pred_mat_tt = get_tissue_wise_seg(pred_mat, tt, params['dilation'])\n",
    "    \n",
    "    # Two-stage dust removal\n",
    "    temp_clean = cc3d.dust(\n",
    "        pred_mat_tt,\n",
    "        threshold=params['min_volume'],\n",
    "        connectivity=params['connectivity']\n",
    "    )\n",
    "    final_clean = cc3d.dust(\n",
    "        temp_clean,\n",
    "        threshold=params['threshold'],\n",
    "        connectivity=params['connectivity']\n",
    "    )\n",
    "    \n",
    "    rm_dust_mask = np.logical_and(pred_mat_tt==1, final_clean==0)\n",
    "    pred_mat[rm_dust_mask] = 0\n",
    "    return rm_dust_mask\n",
    "\n",
    "def enhanced_fill_holes(pred_mat, tt, label, rm_dust_mask):\n",
    "    \"\"\"Enhanced hole filling with structure preservation\"\"\"\n",
    "    hole_params = {\n",
    "        'ET': {'threshold': 10, 'connectivity': 6, 'max_hole_size': 15},\n",
    "        'TC': {'threshold': 20, 'connectivity': 18, 'max_hole_size': 30},\n",
    "        'WT': {'threshold': 40, 'connectivity': 26, 'max_hole_size': 50}\n",
    "    }\n",
    "    \n",
    "    params = hole_params[tt]\n",
    "    pred_mat_tt = get_tissue_wise_seg(pred_mat, tt)\n",
    "    \n",
    "    # Detect holes more precisely\n",
    "    tt_holes = 1 - pred_mat_tt\n",
    "    tt_holes_rm = cc3d.dust(\n",
    "        tt_holes,\n",
    "        threshold=params['threshold'],\n",
    "        connectivity=params['connectivity']\n",
    "    )\n",
    "    \n",
    "    # Remove overly large holes\n",
    "    large_holes = cc3d.dust(\n",
    "        tt_holes_rm,\n",
    "        threshold=params['max_hole_size'],\n",
    "        connectivity=params['connectivity']\n",
    "    )\n",
    "    tt_holes_rm[large_holes > 0] = 0\n",
    "    \n",
    "    tt_filled = 1 - tt_holes_rm\n",
    "    holes_mask = np.logical_and.reduce((\n",
    "        tt_filled == 1,\n",
    "        pred_mat == 0,\n",
    "        rm_dust_mask,\n",
    "        cc3d.dust(tt_filled, threshold=5, connectivity=6) > 0  # Ensure connected\n",
    "    ))\n",
    "    pred_mat[holes_mask] = label\n",
    "\n",
    "def rm_dust_fh(pred_mat):\n",
    "    \"\"\"Optimized processing pipeline with ET-first strategy\"\"\"\n",
    "    # Initial cleanup\n",
    "    pred_mat = adaptive_rm_dust(pred_mat)\n",
    "    \n",
    "    # ET-specific processing\n",
    "    rm_et_mask = enhanced_rm_tt_dust(pred_mat, 'ET')\n",
    "    enhanced_fill_holes(pred_mat, 'TC', 1, rm_et_mask)\n",
    "    \n",
    "    # TC processing\n",
    "    rm_tc_mask = enhanced_rm_tt_dust(pred_mat, 'TC')\n",
    "    enhanced_fill_holes(pred_mat, 'WT', 2, rm_tc_mask)\n",
    "    \n",
    "    # Final WT processing\n",
    "    _ = enhanced_rm_tt_dust(pred_mat, 'WT')\n",
    "    \n",
    "    # Final morphological smoothing\n",
    "    for label in [1, 2, 3]:\n",
    "        if label in pred_mat:\n",
    "            label_mask = (pred_mat == label)\n",
    "            pred_mat[label_mask & ~cc3d.dust(label_mask, threshold=10, connectivity=6)] = 0\n",
    "    \n",
    "    return pred_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "brats_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T06:56:31.838102Z",
     "iopub.status.busy": "2025-07-12T06:56:31.837866Z",
     "iopub.status.idle": "2025-07-12T06:56:31.875799Z",
     "shell.execute_reply": "2025-07-12T06:56:31.875029Z",
     "shell.execute_reply.started": "2025-07-12T06:56:31.838085Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from scipy.ndimage import map_coordinates, gaussian_filter, zoom\n",
    "#from ..processing.preprocess import znorm_rescale, center_crop\n",
    "\n",
    "class BratsDataset(Dataset):\n",
    "    \"\"\"Dataset class for loading BraTS training and test data with advanced augmentations.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory of training or test data.\n",
    "        mode: Either 'train' or 'test' specifying which data is being loaded.\n",
    "        augment: Whether to apply data augmentations (only for training mode).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, mode, augment=False, max_subjects=None):\n",
    "        \"\"\"Initialize the dataset with augmentation parameters.\"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.subject_list = sorted(os.listdir(data_dir))  # sorted for reproducibility\n",
    "        if max_subjects is not None:\n",
    "            self.subject_list = self.subject_list[:max_subjects]\n",
    "        self.mode = mode\n",
    "        self.augment = augment and mode == 'train'  # Only augment training data\n",
    "        \n",
    "        # Enhanced augmentation parameters for stronger augmentation\n",
    "        self.flip_prob = 0.7          # Increased probability of applying random flips\n",
    "        self.rotation_range = 20       # Increased degrees (Â± range for random rotations)\n",
    "        self.noise_std = 0.15          # Increased standard deviation of Gaussian noise\n",
    "        self.gamma_range = (0.6, 1.4)  # Wider range for gamma correction\n",
    "        self.elastic_alpha = (0., 1200.)  # Increased magnitude range for elastic deformation\n",
    "        self.elastic_sigma = (8., 15.)   # Wider smoothness range for elastic deformation\n",
    "        self.bias_field_scale = 0.4      # Increased strength of bias field artifact\n",
    "        \n",
    "        # New augmentation parameters for stronger augmentation\n",
    "        self.scale_range = (0.85, 1.15)  # Random scaling factor\n",
    "        self.contrast_range = (0.7, 1.3)  # Contrast adjustment range\n",
    "        self.brightness_range = (-0.1, 0.1)  # Brightness adjustment range\n",
    "        self.blur_prob = 0.2           # Probability of applying Gaussian blur\n",
    "        self.blur_sigma = (0.5, 1.5)   # Blur sigma range\n",
    "        self.cutout_prob = 0.15        # Probability of applying cutout\n",
    "        self.cutout_size = (10, 30)    # Cutout size range\n",
    "        \n",
    "        # Modality-specific augmentation parameters\n",
    "        self.modality_names = ['t1c', 't1n', 't2f', 't2w']\n",
    "        self.modality_specific_prob = 0.3  # Probability of applying modality-specific augmentations\n",
    "        \n",
    "        # T1c-specific (contrast-enhanced): More aggressive contrast/brightness\n",
    "        self.t1c_contrast_range = (0.6, 1.4)\n",
    "        self.t1c_brightness_range = (-0.15, 0.15)\n",
    "        \n",
    "        # T1n-specific (native): More noise augmentation\n",
    "        self.t1n_noise_multiplier = 1.5\n",
    "        \n",
    "        # T2f-specific (FLAIR): More bias field and gamma correction\n",
    "        self.t2f_bias_multiplier = 1.3\n",
    "        self.t2f_gamma_range = (0.5, 1.5)\n",
    "        \n",
    "        # T2w-specific: More blur and elastic deformation\n",
    "        self.t2w_blur_multiplier = 1.5\n",
    "        self.t2w_elastic_multiplier = 1.2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subject_list)\n",
    "    \n",
    "    def load_nifti(self, subject_name, suffix):\n",
    "        \"\"\"Loads nifti file for given subject and suffix.\n",
    "        \n",
    "        Args:\n",
    "            subject_name: Name of the subject directory.\n",
    "            suffix: Modality suffix (e.g., 't1c', 'seg').\n",
    "            \n",
    "        Returns:\n",
    "            Loaded nibabel nifti object.\n",
    "        \"\"\"\n",
    "        nifti_filename = f'{subject_name}-{suffix}.nii'\n",
    "        nifti_path = os.path.join(self.data_dir, subject_name, nifti_filename)\n",
    "        return nib.load(nifti_path)\n",
    "    \n",
    "    def load_subject_data(self, subject_name):\n",
    "        \"\"\"Loads images and segmentation (if in train mode) for a subject.\n",
    "        \n",
    "        Args:\n",
    "            subject_name: Name of the subject directory.\n",
    "            \n",
    "        Returns:\n",
    "            For training: tuple of (modalities_data, seg_data)\n",
    "            For testing: modalities_data\n",
    "        \"\"\"\n",
    "        modalities_data = []\n",
    "        for suffix in self.modality_names:  # All 4 standard BraTS modalities\n",
    "            modality_data = self.load_nifti(subject_name, suffix).get_fdata()\n",
    "            modalities_data.append(modality_data)\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            seg_data = self.load_nifti(subject_name, 'seg').get_fdata()\n",
    "            return modalities_data, seg_data\n",
    "        return modalities_data\n",
    "    \n",
    "    def apply_augmentations(self, imgs, seg=None):\n",
    "        \"\"\"Apply random augmentations to images and segmentation with stronger augmentation.\n",
    "        \n",
    "        Args:\n",
    "            imgs: List of modality images.\n",
    "            seg: Optional segmentation mask.\n",
    "            \n",
    "        Returns:\n",
    "            Augmented images and segmentation (if provided).\n",
    "        \"\"\"\n",
    "        if not self.augment:\n",
    "            return imgs, seg\n",
    "            \n",
    "        # Random flips (increased probability)\n",
    "        if random.random() < self.flip_prob:\n",
    "            axis = random.randint(0, 2)  # Random axis (0, 1, or 2)\n",
    "            imgs = [np.flip(img, axis=axis) for img in imgs]\n",
    "            if seg is not None:\n",
    "                seg = np.flip(seg, axis=axis)\n",
    "        \n",
    "        # Random scaling (new augmentation)\n",
    "        if random.random() < 0.4:\n",
    "            scale_factor = random.uniform(*self.scale_range)\n",
    "            imgs, seg = self.scale_images(imgs, seg, scale_factor)\n",
    "                \n",
    "        # Random rotation (increased probability)\n",
    "        if random.random() < 0.4:\n",
    "            angle = random.uniform(-self.rotation_range, self.rotation_range)\n",
    "            imgs = [self.rotate_image(img, angle) for img in imgs]\n",
    "            if seg is not None:\n",
    "                seg = self.rotate_image(seg, angle, is_seg=True)\n",
    "                \n",
    "        # Elastic deformations (increased probability)\n",
    "        if random.random() < 0.4:\n",
    "            imgs, seg = self.elastic_deform(imgs, seg)\n",
    "        \n",
    "        # Cutout augmentation (new)\n",
    "        if random.random() < self.cutout_prob:\n",
    "            imgs = self.apply_cutout(imgs)\n",
    "                \n",
    "        # Intensity transformations (increased probabilities)\n",
    "        for i in range(len(imgs)):\n",
    "            modality = self.modality_names[i]\n",
    "            \n",
    "            # Standard intensity augmentations\n",
    "            if random.random() < 0.4:  # Gaussian noise\n",
    "                noise_std = self.noise_std\n",
    "                if modality == 't1n':  # More noise for T1n\n",
    "                    noise_std *= self.t1n_noise_multiplier\n",
    "                noise = np.random.normal(0, noise_std, imgs[i].shape)\n",
    "                imgs[i] = imgs[i] + noise\n",
    "                \n",
    "            if random.random() < 0.4:  # Gamma correction\n",
    "                gamma_range = self.gamma_range\n",
    "                if modality == 't2f':  # More aggressive gamma for T2f\n",
    "                    gamma_range = self.t2f_gamma_range\n",
    "                gamma = random.uniform(*gamma_range)\n",
    "                imgs[i] = np.sign(imgs[i]) * (np.abs(imgs[i]) ** gamma)\n",
    "                \n",
    "            if random.random() < 0.4:  # Bias field artifact\n",
    "                bias_scale = self.bias_field_scale\n",
    "                if modality == 't2f':  # Stronger bias field for T2f\n",
    "                    bias_scale *= self.t2f_bias_multiplier\n",
    "                imgs[i] = self.add_bias_field(imgs[i], bias_scale)\n",
    "            \n",
    "            # New intensity augmentations\n",
    "            if random.random() < 0.3:  # Contrast adjustment\n",
    "                contrast_range = self.contrast_range\n",
    "                if modality == 't1c':  # More aggressive contrast for T1c\n",
    "                    contrast_range = self.t1c_contrast_range\n",
    "                contrast = random.uniform(*contrast_range)\n",
    "                imgs[i] = imgs[i] * contrast\n",
    "                \n",
    "            if random.random() < 0.3:  # Brightness adjustment\n",
    "                brightness_range = self.brightness_range\n",
    "                if modality == 't1c':  # More aggressive brightness for T1c\n",
    "                    brightness_range = self.t1c_brightness_range\n",
    "                brightness = random.uniform(*brightness_range)\n",
    "                imgs[i] = imgs[i] + brightness\n",
    "                \n",
    "            if random.random() < self.blur_prob:  # Gaussian blur\n",
    "                blur_sigma = random.uniform(*self.blur_sigma)\n",
    "                if modality == 't2w':  # More blur for T2w\n",
    "                    blur_sigma *= self.t2w_blur_multiplier\n",
    "                imgs[i] = gaussian_filter(imgs[i], sigma=blur_sigma)\n",
    "            \n",
    "            # Apply modality-specific augmentations\n",
    "            if random.random() < self.modality_specific_prob:\n",
    "                imgs[i] = self.apply_modality_specific_augmentation(imgs[i], modality)\n",
    "                \n",
    "        return imgs, seg\n",
    "    \n",
    "    def apply_modality_specific_augmentation(self, img, modality):\n",
    "        \"\"\"Apply modality-specific augmentations.\n",
    "        \n",
    "        Args:\n",
    "            img: Input image.\n",
    "            modality: Modality name ('t1c', 't1n', 't2f', 't2w').\n",
    "            \n",
    "        Returns:\n",
    "            Augmented image.\n",
    "        \"\"\"\n",
    "        if modality == 't1c':\n",
    "            # T1c: Simulate contrast agent variations\n",
    "            if random.random() < 0.5:\n",
    "                # Simulate uneven contrast enhancement\n",
    "                enhancement_field = self.create_enhancement_field(img.shape)\n",
    "                img = img * enhancement_field\n",
    "                \n",
    "        elif modality == 't1n':\n",
    "            # T1n: Add more complex noise patterns\n",
    "            if random.random() < 0.5:\n",
    "                # Add Rician noise (common in MRI)\n",
    "                img = self.add_rician_noise(img)\n",
    "                \n",
    "        elif modality == 't2f':\n",
    "            # T2f: Simulate CSF flow artifacts\n",
    "            if random.random() < 0.5:\n",
    "                # Add flow artifacts\n",
    "                img = self.add_flow_artifacts(img)\n",
    "                \n",
    "        elif modality == 't2w':\n",
    "            # T2w: Add motion artifacts\n",
    "            if random.random() < 0.5:\n",
    "                # Simulate motion artifacts\n",
    "                img = self.add_motion_artifacts(img)\n",
    "                \n",
    "        return img\n",
    "    \n",
    "    def create_enhancement_field(self, shape):\n",
    "        \"\"\"Create a random enhancement field for T1c modality.\"\"\"\n",
    "        # Create low-frequency field\n",
    "        field = np.random.randn(*[s//8 + 1 for s in shape])\n",
    "        field = zoom(field, \n",
    "                    [shape[0]/field.shape[0], \n",
    "                     shape[1]/field.shape[1],\n",
    "                     shape[2]/field.shape[2]], \n",
    "                    order=1)\n",
    "        return 1.0 + 0.3 * np.tanh(field)\n",
    "    \n",
    "    def add_rician_noise(self, img):\n",
    "        \"\"\"Add Rician noise to image.\"\"\"\n",
    "        noise_level = 0.05 * np.std(img)\n",
    "        noise_real = np.random.normal(0, noise_level, img.shape)\n",
    "        noise_imag = np.random.normal(0, noise_level, img.shape)\n",
    "        return np.sqrt((img + noise_real)**2 + noise_imag**2)\n",
    "    \n",
    "    def add_flow_artifacts(self, img):\n",
    "        \"\"\"Add CSF flow artifacts to FLAIR images.\"\"\"\n",
    "        # Create periodic artifacts\n",
    "        z_coords = np.arange(img.shape[2])\n",
    "        artifact_pattern = 0.1 * np.sin(2 * np.pi * z_coords / 10)\n",
    "        artifact_field = np.broadcast_to(artifact_pattern, img.shape)\n",
    "        return img + img * artifact_field\n",
    "    \n",
    "    def add_motion_artifacts(self, img):\n",
    "        \"\"\"Add motion artifacts to images.\"\"\"\n",
    "        # Simulate motion by applying small random translations\n",
    "        shift_x = random.uniform(-2, 2)\n",
    "        shift_y = random.uniform(-2, 2)\n",
    "        from scipy.ndimage import shift\n",
    "        return shift(img, [shift_x, shift_y, 0], mode='constant')\n",
    "    \n",
    "    def scale_images(self, imgs, seg, scale_factor):\n",
    "        \"\"\"Scale images and segmentation by a factor.\"\"\"\n",
    "        scaled_imgs = []\n",
    "        for img in imgs:\n",
    "            scaled_img = zoom(img, scale_factor, order=3)\n",
    "            # Crop or pad to original size\n",
    "            scaled_img = self.resize_to_original(scaled_img, img.shape)\n",
    "            scaled_imgs.append(scaled_img)\n",
    "        \n",
    "        if seg is not None:\n",
    "            scaled_seg = zoom(seg, scale_factor, order=0)\n",
    "            seg = self.resize_to_original(scaled_seg, seg.shape)\n",
    "            \n",
    "        return scaled_imgs, seg\n",
    "    \n",
    "    def resize_to_original(self, img, target_shape):\n",
    "        \"\"\"Resize image to target shape by cropping or padding.\"\"\"\n",
    "        current_shape = img.shape\n",
    "        \n",
    "        # Calculate padding/cropping for each dimension\n",
    "        result = img.copy()\n",
    "        for i in range(len(target_shape)):\n",
    "            diff = target_shape[i] - current_shape[i]\n",
    "            if diff > 0:  # Need to pad\n",
    "                pad_before = diff // 2\n",
    "                pad_after = diff - pad_before\n",
    "                pad_width = [(0, 0)] * len(target_shape)\n",
    "                pad_width[i] = (pad_before, pad_after)\n",
    "                result = np.pad(result, pad_width, mode='constant')\n",
    "            elif diff < 0:  # Need to crop\n",
    "                crop_before = (-diff) // 2\n",
    "                crop_after = current_shape[i] - (-diff) + crop_before\n",
    "                slices = [slice(None)] * len(target_shape)\n",
    "                slices[i] = slice(crop_before, crop_after)\n",
    "                result = result[tuple(slices)]\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def apply_cutout(self, imgs):\n",
    "        \"\"\"Apply cutout augmentation to images.\"\"\"\n",
    "        cutout_imgs = []\n",
    "        for img in imgs:\n",
    "            img_copy = img.copy()\n",
    "            \n",
    "            # Random cutout parameters\n",
    "            cutout_size = random.randint(*self.cutout_size)\n",
    "            x = random.randint(0, max(1, img.shape[0] - cutout_size))\n",
    "            y = random.randint(0, max(1, img.shape[1] - cutout_size))\n",
    "            z = random.randint(0, max(1, img.shape[2] - cutout_size))\n",
    "            \n",
    "            # Apply cutout\n",
    "            img_copy[x:x+cutout_size, y:y+cutout_size, z:z+cutout_size] = 0\n",
    "            cutout_imgs.append(img_copy)\n",
    "            \n",
    "        return cutout_imgs\n",
    "        \n",
    "    def elastic_deform(self, imgs, seg):\n",
    "        \"\"\"Apply elastic deformation to images and segmentation with stronger deformation.\n",
    "        \n",
    "        Args:\n",
    "            imgs: List of modality images.\n",
    "            seg: Optional segmentation mask.\n",
    "            \n",
    "        Returns:\n",
    "            Deformed images and segmentation (if provided).\n",
    "        \"\"\"\n",
    "        shape = imgs[0].shape\n",
    "        alpha = random.uniform(*self.elastic_alpha)  # Deformation magnitude\n",
    "        sigma = random.uniform(*self.elastic_sigma)  # Deformation smoothness\n",
    "        \n",
    "        # Create random displacement fields\n",
    "        dx = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma, mode='constant') * alpha\n",
    "        dy = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma, mode='constant') * alpha\n",
    "        dz = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma, mode='constant') * alpha\n",
    "\n",
    "        # Create coordinate grid\n",
    "        x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]), indexing='ij')\n",
    "        coords = np.array([x + dx, y + dy, z + dz])\n",
    "        \n",
    "        # Apply deformation to each modality (cubic interpolation)\n",
    "        deformed_imgs = [map_coordinates(img, coords, order=3, mode='reflect') for img in imgs]\n",
    "        \n",
    "        # Apply to segmentation (nearest neighbor interpolation)\n",
    "        if seg is not None:\n",
    "            seg = map_coordinates(seg, coords, order=0, mode='constant')\n",
    "            \n",
    "        return deformed_imgs, seg\n",
    "        \n",
    "    def add_bias_field(self, image, bias_scale=None):\n",
    "        \"\"\"Add MRI bias field artifact to an image.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image to modify.\n",
    "            bias_scale: Optional bias field scale override.\n",
    "            \n",
    "        Returns:\n",
    "            Image with simulated bias field.\n",
    "        \"\"\"\n",
    "        if bias_scale is None:\n",
    "            bias_scale = self.bias_field_scale\n",
    "            \n",
    "        shape = image.shape\n",
    "        # Create low-frequency random field\n",
    "        rand_field = np.random.randn(*[s//16 + 1 for s in shape])\n",
    "        rand_field = zoom(rand_field, \n",
    "                         [shape[0]/rand_field.shape[0], \n",
    "                          shape[1]/rand_field.shape[1],\n",
    "                          shape[2]/rand_field.shape[2]], \n",
    "                         order=1)\n",
    "        \n",
    "        # Create smooth multiplicative bias field\n",
    "        bias_field = np.exp(bias_scale * rand_field)\n",
    "        return image * bias_field\n",
    "        \n",
    "    def rotate_image(self, image, angle, is_seg=False):\n",
    "        \"\"\"Rotate image by specified angle around axial plane.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image to rotate.\n",
    "            angle: Rotation angle in degrees.\n",
    "            is_seg: Whether the image is a segmentation mask.\n",
    "            \n",
    "        Returns:\n",
    "            Rotated image.\n",
    "        \"\"\"\n",
    "        from scipy.ndimage import rotate\n",
    "        axes = (0, 1)  # Rotate in axial plane\n",
    "        order = 0 if is_seg else 3  # Nearest neighbor for seg, cubic for images\n",
    "        return rotate(image, angle, axes=axes, reshape=False, order=order, mode='constant')\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Load and process a single subject's data.\n",
    "        \n",
    "        Args:\n",
    "            idx: Index of the subject to load.\n",
    "            \n",
    "        Returns:\n",
    "            For training: (subject_name, modalities, segmentation)\n",
    "            For testing: (subject_name, modalities)\n",
    "        \"\"\"\n",
    "        subject_name = self.subject_list[idx]\n",
    "\n",
    "        # Load the data\n",
    "        if self.mode == 'train':\n",
    "            imgs, seg = self.load_subject_data(subject_name)\n",
    "        else:\n",
    "            imgs = self.load_subject_data(subject_name)\n",
    "            seg = None\n",
    "\n",
    "        # Apply augmentations (only for training when augment=True)\n",
    "        imgs, seg = self.apply_augmentations(imgs, seg)\n",
    "\n",
    "        # Standard preprocessing\n",
    "        imgs = [znorm_rescale(img) for img in imgs]  # Normalize each modality\n",
    "        imgs = [center_crop(img) for img in imgs]    # Center crop\n",
    "        \n",
    "        # Convert to tensors\n",
    "        imgs = [torch.from_numpy(img[None, ...].astype(np.float32)) for img in imgs]  # Add channel dim\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            seg = center_crop(seg)\n",
    "            seg = torch.from_numpy(seg[None, ...].astype(np.float32))  # Add channel dim\n",
    "            return subject_name, imgs, seg\n",
    "        \n",
    "        return subject_name, imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "general_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T11:36:24.945723Z",
     "iopub.status.busy": "2025-07-12T11:36:24.945393Z",
     "iopub.status.idle": "2025-07-12T11:36:24.961355Z",
     "shell.execute_reply": "2025-07-12T11:36:24.960759Z",
     "shell.execute_reply.started": "2025-07-12T11:36:24.945698Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "#from ..processing.preprocess import undo_center_crop\n",
    "\n",
    "def seg_to_one_hot_channels(seg):\n",
    "    \"\"\"Converts segmentation to 3 channels, each a one-hot encoding of a tumour region label.\n",
    "\n",
    "    Args:\n",
    "        seg: Tensor of shape B1HWD, where each entry is a voxel label.\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape B3HWD, where each channel is one-hot encoding of a disjoint region.\n",
    "    \"\"\"\n",
    "    B, _, H, W, D = seg.shape\n",
    "    seg3 = torch.zeros((B, 3, H, W, D), device=seg.device)\n",
    "    \n",
    "    # Squeeze the channel dimension for comparison\n",
    "    seg = seg.squeeze(1)  # Now shape [B, H, W, D]\n",
    "    \n",
    "    for channel_value in [1, 2, 3]:\n",
    "        # Create mask and add channel dimension back\n",
    "        mask = (seg == channel_value).float().unsqueeze(1)  # Shape [B, 1, H, W, D]\n",
    "        seg3[:, channel_value-1:channel_value, :, :, :] = mask\n",
    "    \n",
    "    return seg3\n",
    "\n",
    "def disjoint_to_overlapping(seg_disjoint):\n",
    "    \"\"\"Converts tensor representing one-hot encoding of disjoint regions to that of overlapping ones.\n",
    "\n",
    "    Args:\n",
    "        seg_disjoint: Tensor of shape B3HWD, where each channel is one-hot encoding of a disjoint region. \n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape B3HWD, where each channel is one-hot encoding of an overlapping region.\n",
    "    \"\"\"\n",
    "    seg_overlapping = torch.zeros_like(seg_disjoint)\n",
    "    seg_overlapping[:,0] = seg_disjoint[:, 0] + seg_disjoint[:, 1] + seg_disjoint[:, 2] #WHOLE TUMOR\n",
    "    seg_overlapping[:,1] = seg_disjoint[:, 0] + seg_disjoint[:, 2] #TUMOR CORE\n",
    "    seg_overlapping[:,2] = seg_disjoint[:, 2] #ENHANCING TUMOR\n",
    "    return seg_overlapping\n",
    "\n",
    "def overlapping_probs_to_preds(output, t1=0.45, t2=0.4, t3=0.45):\n",
    "    \"\"\"Converts output of model trained on overlapping regions to one-hot encodings of disjoint regions.\n",
    "\n",
    "    Args:\n",
    "        output: Tensor of shape B3HWD. Output of model, representing probabilties each voxel belongs to each overlapping region.\n",
    "        t1: Threshold for being in whole tumor (WT). Defaults to 0.45.\n",
    "        t2: Threshold for being in tumor core (TC). Defaults to 0.4.\n",
    "        t3: Threshold for being in enhancing tumor (ET). Defaults to 0.45.\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape B3HWD, where each channel is one-hot encoding of a disjoint region.\n",
    "    \"\"\"\n",
    "    output = output.cpu().detach()\n",
    "    c1, c2, c3 = output[:, 0] > t1, output[:, 1] > t2, output[:, 2] > t3\n",
    "    preds = (c1 > 0).to(torch.uint8) # NCR\n",
    "    preds[(c2 == False) * (c1 == True)] = 2 # ED\n",
    "    preds[(c3 == True) * (c1 == True)] = 3 # ET\n",
    "    output_plot = torch.zeros_like(output)\n",
    "    output_plot[:, 0] = (preds == 1).to(torch.uint8) #NCR\n",
    "    output_plot[:, 1] = (preds == 2).to(torch.uint8) #ED\n",
    "    output_plot[:, 2] = (preds == 3).to(torch.uint8) #ET\n",
    "    output_plot = output_plot.to(torch.uint8)\n",
    "    return output_plot\n",
    "\n",
    "def disjoint_probs_to_preds(output, t=0.5):\n",
    "    \"\"\"Converts output of model trained on disjoint regions to one-hot encodings of disjoint regions.\n",
    "\n",
    "    Args:\n",
    "        output: Tensor of shape B3HWD. Output of model, representing probabilties each voxel belongs to each disjoint region.\n",
    "        t: Threshold value. If channel probability for a voxel is the maximum across all channels AND greater than this threshold, channel value will be encoded as 1, otherwise 0. Defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape B3HWD, where each channel is one-hot encoding of a disjoint region.\n",
    "    \"\"\"\n",
    "    output = output.cpu().detach()\n",
    "    c1, c2, c3 = output[:, 0], output[:, 1], output[:, 2]\n",
    "    max_label = torch.max(torch.max(c1, c2), c3)\n",
    "    preds = torch.zeros_like(output)\n",
    "    preds[:, 0] = torch.where(c1 < max_label, torch.tensor(0), max_label)\n",
    "    preds[:, 1] = torch.where(c2 < max_label, torch.tensor(0), max_label)\n",
    "    preds[:, 2] = torch.where(c3 < max_label, torch.tensor(0), max_label)\n",
    "    output_plot = torch.zeros_like(output)\n",
    "    for c in range(0, 3):\n",
    "        output_plot[:, c] = torch.where(preds[:, c] > t, torch.tensor(1.), torch.tensor(0.))\n",
    "    output_plot = output_plot.to(torch.uint8)\n",
    "    return output_plot\n",
    "\n",
    "def probs_to_preds(output, training_regions):\n",
    "    \"\"\"Converts tensor of voxel probabilities to tensor of disjoint region labels.\n",
    "\n",
    "    Args:\n",
    "        output: Tensor of shape B3HWD. Output of model, representing probabilties each voxel belongs to a region.\n",
    "        training_regions: Whether probabilities relate to overlapping or disjoint regions.\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape B3HWD, where each channel is one-hot encoding of a disjoint region.\n",
    "    \"\"\"\n",
    "    if training_regions == 'overlapping':\n",
    "        preds = overlapping_probs_to_preds(output)\n",
    "    elif training_regions == 'disjoint':\n",
    "        preds = disjoint_probs_to_preds(output)\n",
    "\n",
    "    return preds\n",
    "\n",
    "def fetch_affine_header(subject_name, data_dir):\n",
    "    \"\"\"Finds affine and header of a modality nifti for given subject.\n",
    "\n",
    "    Args:\n",
    "        subject_name: Name of given subject. Will also be name of folder containing MRI niftis.\n",
    "        data_dir: Parent directory of subject data folder.\n",
    "\n",
    "    Returns:\n",
    "        The affine and header objects from a modality nifti of the subject.\n",
    "    \"\"\"\n",
    "\n",
    "    modality_nifti_filename = f'{subject_name}-t1c.nii'\n",
    "    modality_nifti_path = os.path.join(data_dir, subject_name, modality_nifti_filename)\n",
    "    nifti = nib.load(modality_nifti_path)\n",
    "    \n",
    "    return nifti.affine, nifti.header\n",
    "\n",
    "def one_hot_channels_to_three_labels(pred):\n",
    "    \"\"\"Converts tensor of one-hot encodings of disjoint regions to be single channel. Each voxel is assigned a single disjoint region label.\n",
    "\n",
    "    Args:\n",
    "        pred: Array-like of shape 3HWD, where channels are one-hot encodings of disjoint regions.\n",
    "\n",
    "    Returns:\n",
    "        Array-like of shape HWD, associating to each voxel a single disjoint region label.\n",
    "    \"\"\"\n",
    "    return pred[0] + pred[1]*2 + pred[2]*3\n",
    "\n",
    "def save_pred_as_nifti(pred, save_dir, data_dir, subject_name, postprocess_function=None):\n",
    "    \"\"\"Saves predicted segmentation as nifti file with affine and header objects matching its MRI niftis.\n",
    "\n",
    "    Args:\n",
    "        pred: Tensor of shape HWD, associating to each voxel a single disjoint region label.\n",
    "        save_dir: Directory in which to save the predicted segmentation nifti.\n",
    "        data_dir: Parent directory of subject data folder.\n",
    "        subject_name: Name of given subject. Will also be name of folder containing MRI niftis.\n",
    "        postprocess_function: If provided, performs this postprocessing on the prediction. Defaults to None.\n",
    "    \"\"\"\n",
    "    # Convert back from 3 one-hot encoded channels to 1 channel with 3 tumour region labels\n",
    "    pred = np.array(pred)\n",
    "    pred_for_nifti = one_hot_channels_to_three_labels(pred)\n",
    "    pred_for_nifti = np.squeeze(pred_for_nifti)\n",
    "    pred_for_nifti = undo_center_crop(pred_for_nifti)\n",
    "    pred_for_nifti = pred_for_nifti.astype(np.uint8)\n",
    "\n",
    "    if postprocess_function:\n",
    "        pred_for_nifti = postprocess_function(pred_for_nifti)\n",
    "\n",
    "    affine, header = fetch_affine_header(subject_name, data_dir)\n",
    "    pred_nifti = nib.nifti1.Nifti1Image(pred_for_nifti, affine=affine, header=header)\n",
    "    filename = f'{subject_name}-seg.nii'\n",
    "    nib.nifti1.save(pred_nifti, os.path.join(save_dir, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_utils.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T06:56:31.902235Z",
     "iopub.status.busy": "2025-07-12T06:56:31.902033Z",
     "iopub.status.idle": "2025-07-12T06:56:31.923055Z",
     "shell.execute_reply": "2025-07-12T06:56:31.922283Z",
     "shell.execute_reply.started": "2025-07-12T06:56:31.902211Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"This module contains utility functions for training models.\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#from ..datasets import brats_dataset\n",
    "#from .general_utils import seg_to_one_hot_channels, disjoint_to_overlapping\n",
    "\n",
    "def load_or_initialize_training(model, optimizer, latest_ckpt_path, train_with_val=False):\n",
    "    \"\"\"Loads training checkpoint if it exists, or initializes training from scratch.\n",
    "\n",
    "    Args:\n",
    "        model: The PyTorch model to be trained.\n",
    "        optimizer: The optimizer used for training.\n",
    "        latest_ckpt_path: The path to the latest model checkpoint.\n",
    "        train_with_val: If True, also returns best saved validation loss and dice. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        The starting epoch number.\n",
    "        If 'train_with_val' is True, also returns best saved validation loss and dice.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(latest_ckpt_path):\n",
    "        epoch_start = 1\n",
    "        if train_with_val:\n",
    "            best_vloss = float('inf')\n",
    "            best_dice = 0\n",
    "        print('No training checkpoint found. Will start training from scratch.')\n",
    "    else:\n",
    "        print('Training checkpoint found. Loading checkpoint...')\n",
    "        checkpoint = torch.load(latest_ckpt_path,  weights_only=False)\n",
    "        epoch_start = checkpoint['epoch'] + 1\n",
    "        model.load_state_dict(checkpoint['model_sd'])\n",
    "        optimizer.load_state_dict(checkpoint['optim_sd'])\n",
    "        if train_with_val:\n",
    "            best_vloss = checkpoint['vloss']\n",
    "            best_dice = checkpoint['dice']\n",
    "        print(f'Checkpoint loaded. Will continue training from epoch {epoch_start}.')\n",
    "\n",
    "    if train_with_val:\n",
    "        return epoch_start, best_vloss, best_dice\n",
    "    return epoch_start\n",
    "\n",
    "def make_dataloader(data_dir, shuffle, mode, augment, batch_size=1, max_subjects=None):\n",
    "    dataset = BratsDataset(data_dir, mode=mode, augment=augment, max_subjects=max_subjects)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=1, pin_memory=True)\n",
    "    return dataloader\n",
    "\n",
    "def exp_decay_learning_rate(optimizer, epoch, init_lr, decay_rate):\n",
    "    \"\"\"Exponentially decays learning rate of optimizer at given epoch.\"\"\"\n",
    "    lr = init_lr * (decay_rate ** (epoch-1))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def compute_loss(output, seg, loss_functs, loss_weights):\n",
    "    \"\"\"Computes weighted loss between model output and ground truth, summed across each region.\"\"\"\n",
    "    loss = 0.\n",
    "    for n, loss_function in enumerate(loss_functs):      \n",
    "        temp = 0\n",
    "        for i in range(3):\n",
    "            temp += loss_function(output[:,i:i+1].cuda(), seg[:,i:i+1].cuda())\n",
    "\n",
    "        loss += temp * loss_weights[n]\n",
    "    return loss\n",
    "\n",
    "def train_one_epoch(model, optimizer, train_loader, loss_functions, loss_weights, training_regions):\n",
    "    \"\"\"Performs one training loop of model according to given optimizer, loss functions and associated weights.\n",
    "\n",
    "    Args:\n",
    "        model: The PyTorch model to be trained.\n",
    "        optimizer: The optimizer used for training.\n",
    "        train_loader: The dataloader for training data.\n",
    "        loss_functions: List of loss functions.\n",
    "        loss_weights: List of associated weightings for each loss function.\n",
    "        training_regions: String specifying whether 'disjoint' or 'overlapping' regions will be used for training.\n",
    "\n",
    "    Returns:\n",
    "        The average training loss over the epoch.\n",
    "    \"\"\"\n",
    "    losses_over_epoch = []\n",
    "    for _, imgs, seg in train_loader:\n",
    "        model.train()\n",
    "\n",
    "        # Move data to GPU.\n",
    "        imgs = [img.cuda() for img in imgs] # img is B1HWD\n",
    "        seg = seg.cuda()\n",
    "\n",
    "        # Split segmentation into 3 channels.\n",
    "        seg = seg_to_one_hot_channels(seg)\n",
    "        # seg is B3HWD - each channel is one-hot encoding of a disjoint region\n",
    "\n",
    "        if training_regions == 'overlapping':\n",
    "            seg = disjoint_to_overlapping(seg)\n",
    "            # seg is B3HWD - each channel is one-hot encoding of an overlapping region\n",
    "\n",
    "        x_in = torch.cat(imgs, dim=1) # x_in is B4HWD\n",
    "        outputs = model(x_in)\n",
    "        \n",
    "        # Handle both dictionary output (deep supervision) and single output cases\n",
    "        if isinstance(outputs, dict):\n",
    "            # Compute loss for each output and combine them\n",
    "            loss = 0\n",
    "            for output in outputs.values():\n",
    "                output = output.float()\n",
    "                loss += compute_loss(output, seg, loss_functions, loss_weights)\n",
    "            # Normalize by number of outputs\n",
    "            loss = loss / len(outputs)\n",
    "        else:\n",
    "            # Original single output case\n",
    "            outputs = outputs.float()\n",
    "            loss = compute_loss(outputs, seg, loss_functions, loss_weights)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses_over_epoch.append(loss.detach().cpu())\n",
    "\n",
    "    # Compute loss from the epoch.\n",
    "    average_epoch_loss = np.mean(losses_over_epoch)\n",
    "    return average_epoch_loss\n",
    "\n",
    "\n",
    "\n",
    "def freeze_layers(model, frozen_layers):\n",
    "    \"\"\"Freezes specified model layers. Afterwards parameters in these layers will not be updated when training.\n",
    "\n",
    "    Args:\n",
    "        model: The model to be trained.\n",
    "        frozen_layers: List of strings specifying model layers.\n",
    "    \"\"\"\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        needs_freezing = False\n",
    "        for layer in frozen_layers:\n",
    "            if layer in name:\n",
    "                needs_freezing = True\n",
    "                break\n",
    "        if needs_freezing:\n",
    "            print(f'Freezing parameter {name}.')\n",
    "            param.requires_grad = False\n",
    "\n",
    "def check_frozen(model, frozen_layers):\n",
    "    \"\"\"Iterates through model layers and checks whether specified layers are frozen.\n",
    "\n",
    "    Args:\n",
    "        model: The model to be trained.\n",
    "        frozen_layers: List of strings specifying model layers.\n",
    "    \"\"\"\n",
    "    for name, param in model.named_parameters():\n",
    "        needs_freezing = False\n",
    "        for layer in frozen_layers:\n",
    "            if layer in name:\n",
    "                needs_freezing = True\n",
    "                break\n",
    "        if needs_freezing:\n",
    "            if param.requires_grad:\n",
    "                print(f'Warning! Param {name} should not require grad but does.')\n",
    "                break\n",
    "            else:\n",
    "                print(f'Parameter {name} is frozen.')\n",
    "\n",
    "# Example parts of unet_3d model to freeze\n",
    "# 'encoder': ['Conv1', 'Conv2', 'Conv3', 'Conv4', 'Conv5', 'Conv6', 'Conv7'],\n",
    "# 'decoder': ['Up6', 'Up_conv6', 'Up5', 'Up_conv5', 'Up4', 'Up_conv4', 'Up3', 'Up_conv3', 'Conv_1x13', 'Up2', 'Up_conv2', 'Conv_1x12', 'Up1', 'Up_conv1', 'Conv_1x11'],\n",
    "# 'middle' : ['Conv5', 'Conv6', 'Conv7', 'Up6', 'Up_conv6', 'Up5', 'Up_conv5', 'Up4', 'Up_conv4'],\n",
    "# 'none' : [],\n",
    "# 'deep_decoder': ['Up6', 'Up_conv6', 'Up5', 'Up_conv5', 'Up4', 'Up_conv4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enhanced3dunet.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T06:56:31.923916Z",
     "iopub.status.busy": "2025-07-12T06:56:31.923706Z",
     "iopub.status.idle": "2025-07-12T06:56:31.944643Z",
     "shell.execute_reply": "2025-07-12T06:56:31.943906Z",
     "shell.execute_reply.started": "2025-07-12T06:56:31.923900Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Contains the architecture for the baseline 3D U-Net model, based on NVIDIA's optimized U-Net.\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# instance norm    \n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out1,ch_out2,k1,k2,s1,s2):\n",
    "        super(conv_block,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.InstanceNorm3d(ch_in),\n",
    "            nn.Conv3d(ch_in, ch_out1, kernel_size=k1,stride=s1,padding=1,bias=True),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.InstanceNorm3d(ch_out1),\n",
    "            nn.Conv3d(ch_out1, ch_out2, kernel_size=k2,stride=s2,padding=1,bias=True),\n",
    "            nn.LeakyReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "      \n",
    "class up_conv(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out):\n",
    "        super(up_conv,self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            #nn.ConvTranspose3d(ch_in, ch_out,kernel_size=2,stride=2,padding=1,bias=True)\n",
    "            nn.ConvTranspose3d(ch_in, ch_out,kernel_size=2,stride=2,padding=1,bias=True,output_padding=1,dilation=2),\n",
    "            #nn.Upsample(scale_factor=2),\n",
    "            nn.InstanceNorm3d(ch_in),\n",
    " \t        nn.LeakyReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        #print(x.device)\n",
    "        x = self.up(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# 3d unet with optimized instance norm    \n",
    "class U_Net3d(nn.Module):\n",
    "    def __init__(self,img_ch=4,output_ch=3):\n",
    "        super(U_Net3d,self).__init__()\n",
    "        nf= 8\n",
    "        self.Maxpool = nn.MaxPool3d(kernel_size=2,stride=2).to(device='cuda:0')\n",
    "        self.Conv1 = conv_block(ch_in=img_ch,ch_out1=nf*2,ch_out2=nf*2,k1=3,k2=3,s1=1,s2=1).to(device='cuda:0')\n",
    "        self.Conv2 = conv_block(ch_in=nf*2,ch_out1=nf*3,ch_out2=nf*3,k1=3,k2=3,s1=2,s2=1).to(device='cuda:0')\n",
    "        self.Conv3 = conv_block(ch_in=nf*3,ch_out1=nf*4,ch_out2=nf*4,k1=3,k2=3,s1=2,s2=1).to(device='cuda:0')\n",
    "        self.Conv4 = conv_block(ch_in=nf*4,ch_out1=nf*6,ch_out2=nf*6,k1=3,k2=3,s1=2,s2=1).to(device='cuda:0')\n",
    "        self.Conv5 = conv_block(ch_in=nf*6,ch_out1=nf*8,ch_out2=nf*8,k1=3,k2=3,s1=2,s2=1).to(device='cuda:0')\n",
    "        self.Conv6 = conv_block(ch_in=nf*8,ch_out1=nf*12,ch_out2=nf*12,k1=3,k2=3,s1=2,s2=1).to(device='cuda:0')\n",
    "        self.Conv7 = conv_block(ch_in=nf*12,ch_out1=nf*16,ch_out2=nf*16,k1=3,k2=3,s1=2,s2=1).to(device='cuda:0')\n",
    "\n",
    "        self.Up6 = up_conv(ch_in=nf*16,ch_out=nf*12).to(device='cuda:0')\n",
    "        self.Up_conv6 = conv_block(ch_in=nf*24, ch_out1=nf*12, ch_out2=nf*12,k1=3,k2=3,s1=1,s2=1).to(device='cuda:0')\n",
    "        \n",
    "        self.Up5 = up_conv(ch_in=nf*12,ch_out=nf*8).to(device='cuda:0')\n",
    "        self.Up_conv5 = conv_block(ch_in=nf*16, ch_out1=nf*8, ch_out2=nf*8,k1=3,k2=3,s1=1,s2=1).to(device='cuda:0')\n",
    "\n",
    "        self.Up4 = up_conv(ch_in=nf*8,ch_out=nf*6).to(device='cuda:0')\n",
    "        self.Up_conv4 = conv_block(ch_in=nf*12, ch_out1=nf*6, ch_out2=nf*6,k1=3,k2=3,s1=1,s2=1).to(device='cuda:0')\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=nf*6,ch_out=nf*4).to(device='cuda:0')\n",
    "        self.Up_conv3 = conv_block(ch_in=nf*8, ch_out1=nf*4,ch_out2=nf*4,k1=3,k2=3,s1=1,s2=1).to(device='cuda:0')\n",
    "        self.Conv_1x13 = nn.Conv3d(nf*4,output_ch,kernel_size=1,stride=1,padding=0).to(device='cuda:0')\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=output_ch,ch_out=nf*3).to(device='cuda:0')\n",
    "        self.Up_conv2 = conv_block(ch_in=nf*6 , ch_out1=nf*3,ch_out2=nf*3,k1=3,k2=3,s1=1,s2=1).to(device='cuda:0')\n",
    "        self.Conv_1x12 = nn.Conv3d(nf*3,output_ch,kernel_size=1,stride=1,padding=0).to(device='cuda:0')\n",
    "        \n",
    "        self.Up1 = up_conv(ch_in=output_ch,ch_out=nf*2).to(device='cuda:0')\n",
    "        self.Up_conv1 = conv_block(ch_in=nf*4, ch_out1=nf*2,ch_out2=nf*2,k1=3,k2=3,s1=1,s2=1).to(device='cuda:0')\n",
    "        self.Conv_1x11 = nn.Conv3d(nf*2,output_ch,kernel_size=1,stride=1,padding=0).to(device='cuda:0')\n",
    "        \n",
    "        self.Sig =nn.Sigmoid().to(device='cuda:0')\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # encoding path\n",
    "        x = x.to(device='cuda:0')\n",
    "        x1 = self.Conv1(x)\n",
    " \n",
    "        x2 = self.Conv2(x1)       \n",
    "        \n",
    "        x3 = self.Conv3(x2)\n",
    "       \n",
    "        x4 = self.Conv4(x3)       \n",
    "       \n",
    "        x5 = self.Conv5(x4)       \n",
    "        \n",
    "        x6 = self.Conv6(x5)\n",
    "\n",
    "        x7 = self.Conv7(x6)\n",
    "        \n",
    "\n",
    "        # decoding + concat path\n",
    "       \n",
    "        d6 = self.Up6(x7.to(device='cuda:0'))\n",
    "        d6 = torch.cat((x6.to(device='cuda:0'),d6),dim=1)\n",
    "        d6 = self.Up_conv6(d6)\n",
    "\n",
    "        d5 = self.Up5(d6)\n",
    "        d5 = torch.cat((x5.to(device='cuda:0'),d5),dim=1)\n",
    "        d5 = self.Up_conv5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((x4.to(device='cuda:0'),d4),dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((x3.to(device='cuda:0'),d3),dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "        d3 = self.Conv_1x13(d3)\n",
    "        d3 = self.Sig(d3)\n",
    "        \n",
    "        d2 = self.Up2(d3)\n",
    "        d2 = torch.cat((x2.to(device='cuda:0'),d2),dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "        d2 = self.Conv_1x12(d2)\n",
    "        d2 = self.Sig(d2)\n",
    "        \n",
    "        d1 = self.Up1(d2)\n",
    "        d1 = torch.cat((x1.to(device='cuda:0'),d1),dim=1)\n",
    "        d1 = self.Up_conv1(d1)\n",
    "        d1 = self.Conv_1x11(d1)\n",
    "        d1 = self.Sig(d1)\n",
    "\n",
    "        return d1.to(device='cuda:0')\n",
    "    \n",
    "    def __str__(self):\n",
    "        num_params = sum(p.numel() for p in self.parameters())\n",
    "        return f\"UNet_3d (with {num_params:,} parameters)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:15:48.859490Z",
     "iopub.status.busy": "2025-07-12T08:15:48.858951Z",
     "iopub.status.idle": "2025-07-12T10:59:34.588352Z",
     "shell.execute_reply": "2025-07-12T10:59:34.587114Z",
     "shell.execute_reply.started": "2025-07-12T08:15:48.859461Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "TRAINING SUMMARY\n",
      "Data directory: /kaggle/input/brats-africa-dataset/BraTS-Africa Dataset/BraTS-Africa/95_Glioma\n",
      "Model: UNet_3d (with 3,171,417 parameters)\n",
      "Loss functions: [DiceCELoss(\n",
      "  (dice): DiceLoss()\n",
      "  (cross_entropy): CrossEntropyLoss()\n",
      "  (binary_cross_entropy): BCEWithLogitsLoss()\n",
      "), FocalLoss()]\n",
      "Loss weights: [0.7, 0.3]\n",
      "Initial learning rate: 0.0003\n",
      "Max epochs: 20\n",
      "Training regions: overlapping\n",
      "Out directory: /kaggle/working/Result\n",
      "Decay rate: 0.995\n",
      "Backup interval: 10\n",
      "Batch size: 2\n",
      "Scheduler patience: 5\n",
      "---------------------------------------------------\n",
      "Training checkpoint found. Loading checkpoint...\n",
      "Checkpoint loaded. Will continue training from epoch 4.\n",
      "Training starts.\n",
      "Starting epoch 4...\n",
      "Epoch 4 completed. Average loss = 1.9303.\n",
      "Current learning rate: 0.000100\n",
      "Saving model checkpoint...\n",
      "Checkpoint saved successfully.\n",
      "Starting epoch 5...\n",
      "Epoch 5 completed. Average loss = 1.8709.\n",
      "Current learning rate: 0.000100\n",
      "Saving model checkpoint...\n",
      "Checkpoint saved successfully.\n",
      "Starting epoch 6...\n",
      "Epoch 6 completed. Average loss = 1.8130.\n",
      "Current learning rate: 0.000100\n",
      "Saving model checkpoint...\n",
      "Checkpoint saved successfully.\n",
      "Starting epoch 7...\n",
      "Epoch 7 completed. Average loss = 1.7519.\n",
      "Current learning rate: 0.000100\n",
      "Saving model checkpoint...\n",
      "Checkpoint saved successfully.\n",
      "Starting epoch 8...\n",
      "Epoch 8 completed. Average loss = 1.7042.\n",
      "Current learning rate: 0.000100\n",
      "Saving model checkpoint...\n",
      "Checkpoint saved successfully.\n",
      "Starting epoch 9...\n",
      "Epoch 9 completed. Average loss = 1.6799.\n",
      "Current learning rate: 0.000100\n",
      "Saving model checkpoint...\n",
      "Checkpoint saved successfully.\n",
      "Starting epoch 10...\n",
      "Epoch 10 completed. Average loss = 1.6329.\n",
      "Current learning rate: 0.000100\n",
      "Saving model checkpoint...\n",
      "Checkpoint saved successfully.\n",
      "Starting epoch 11...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_117/2445111320.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mout_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/kaggle/working/Result'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_117/2445111320.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_dir, model, loss_functions, loss_weights, init_lr, max_epoch, training_regions, out_dir, decay_rate, backup_interval, batch_size, scheduler_patience)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# The scheduler will adjust LR based on loss plateau\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0maverage_epoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_regions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# Step the scheduler with the current loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_117/3964691188.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, train_loader, loss_functions, loss_weights, training_regions)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \"\"\"\n\u001b[1;32m     82\u001b[0m     \u001b[0mlosses_over_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch import optim\n",
    "import csv\n",
    "import torch.nn as nn\n",
    "\n",
    "from monai.losses import DiceLoss, FocalLoss, DiceCELoss\n",
    "\n",
    "#from ..utils.model_utils import load_or_initialize_training, make_dataloader, exp_decay_learning_rate, train_one_epoch\n",
    "    \n",
    "def train(data_dir, model, loss_functions, loss_weights, init_lr, max_epoch, training_regions='overlapping', out_dir=None, decay_rate=0.995, backup_interval=10, batch_size=2, scheduler_patience=5):\n",
    "    \"\"\"Runs basic training routine.\n",
    "\n",
    "    Args:\n",
    "        data_dir: Directory of training data.\n",
    "        model: The PyTorch model to be trained.\n",
    "        loss_functions: List of loss functions to be used for training.\n",
    "        loss_weights: List of weights corresponding to each loss function.\n",
    "        init_lr: Initial value of learning rate.\n",
    "        max_epoch: Maximum number of epochs to train for.\n",
    "        training_regions: Whether training on 'disjoint' or 'overlapping' regions. Defaults to 'overlapping'.\n",
    "        out_dir: The directory to save model checkpoints and loss values. Defaults to None.\n",
    "        decay_rate: Rate at which to decay the learning rate. Defaults to 0.995.\n",
    "        backup_interval: How often to save a backup checkpoint. Defaults to 10.\n",
    "        batch_size: Batch size of dataloader. Defaults to 1.\n",
    "        scheduler_patience: Patience for ReduceLROnPlateau scheduler. Defaults to 5.\n",
    "    \"\"\"\n",
    "    # Set up directories and paths.\n",
    "    if out_dir is None:\n",
    "        out_dir = os.getcwd()\n",
    "    latest_ckpt_path = os.path.join(out_dir, 'latest_ckpt.pth.tar')\n",
    "    training_loss_path = os.path.join(out_dir, 'training_loss.csv')\n",
    "    backup_ckpts_dir = os.path.join(out_dir, 'backup_ckpts')\n",
    "    if not os.path.exists(backup_ckpts_dir):\n",
    "        os.makedirs(backup_ckpts_dir)\n",
    "        os.system(f'chmod a+rwx {backup_ckpts_dir}')\n",
    "\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(f\"TRAINING SUMMARY\")\n",
    "    print(f\"Data directory: {data_dir}\")\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Loss functions: {loss_functions}\") \n",
    "    print(f\"Loss weights: {loss_weights}\")\n",
    "    print(f\"Initial learning rate: {init_lr}\")\n",
    "    print(f\"Max epochs: {max_epoch}\")\n",
    "    print(f\"Training regions: {training_regions}\")\n",
    "    print(f\"Out directory: {out_dir}\")\n",
    "    print(f\"Decay rate: {decay_rate}\")\n",
    "    print(f\"Backup interval: {backup_interval}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Scheduler patience: {scheduler_patience}\")\n",
    "    print(\"---------------------------------------------------\")\n",
    "\n",
    "    # Enhanced optimizer: AdamW with proper weight decay\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=init_lr, weight_decay=1e-5, amsgrad=True)\n",
    "    \n",
    "    # Learning rate scheduler: ReduceLROnPlateau for adaptive learning rate adjustment\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, \n",
    "                                                     patience=scheduler_patience, verbose=True)\n",
    "\n",
    "    # Check if training for first time or continuing from a saved checkpoint.\n",
    "    epoch_start = load_or_initialize_training(model, optimizer, latest_ckpt_path)\n",
    "\n",
    "    train_loader = make_dataloader(data_dir, shuffle=True, mode='train', augment=True, \n",
    "                                   batch_size=batch_size, max_subjects=60)\n",
    "\n",
    "    print('Training starts.')\n",
    "    for epoch in range(epoch_start, max_epoch+1):\n",
    "        print(f'Starting epoch {epoch}...')\n",
    "\n",
    "        # Note: We now use ReduceLROnPlateau instead of exponential decay\n",
    "        # The scheduler will adjust LR based on loss plateau\n",
    "        \n",
    "        average_epoch_loss = train_one_epoch(model, optimizer, train_loader, loss_functions, loss_weights, training_regions)\n",
    "\n",
    "        # Step the scheduler with the current loss\n",
    "        scheduler.step(average_epoch_loss)\n",
    "\n",
    "        # Save and report loss from the epoch.\n",
    "        save_tloss_csv(training_loss_path, epoch, average_epoch_loss)\n",
    "        print(f'Epoch {epoch} completed. Average loss = {average_epoch_loss:.4f}.')\n",
    "        print(f'Current learning rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "\n",
    "        print('Saving model checkpoint...')\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_sd': model.state_dict(),\n",
    "            'optim_sd': optimizer.state_dict(),\n",
    "            'scheduler_sd': scheduler.state_dict(),\n",
    "            'model': model,\n",
    "            'loss_functions': loss_functions,\n",
    "            'loss_weights': loss_weights,\n",
    "            'init_lr': init_lr,\n",
    "            'training_regions': training_regions,\n",
    "            'decay_rate': decay_rate,\n",
    "            'scheduler_patience': scheduler_patience\n",
    "        }\n",
    "        torch.save(checkpoint, latest_ckpt_path)\n",
    "        if epoch % backup_interval == 0:\n",
    "            torch.save(checkpoint, os.path.join(backup_ckpts_dir, f'epoch{epoch}.pth.tar'))\n",
    "        print('Checkpoint saved successfully.')\n",
    "\n",
    "    \n",
    "def save_tloss_csv(pathname, epoch, tloss):\n",
    "    with open(pathname, mode='a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        if epoch == 1:\n",
    "            writer.writerow(['Epoch', 'Training Loss'])\n",
    "        writer.writerow([epoch, tloss])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #from ..models import unet3d, enhanced3dunet\n",
    "    import torch.nn as nn\n",
    "\n",
    "    data_dir = 'D:/brats2023_updated/ASNR-MICCAI-BraTS2023-SSA-Challenge-TrainingData_V2'\n",
    "    model = U_Net3d()\n",
    "    #model = Optimized3DUNet()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Enhanced loss functions: DiceCE (combines Dice and CrossEntropy) + FocalLoss\n",
    "    loss_functions = [\n",
    "        DiceCELoss(include_background=False, softmax=True, lambda_dice=0.5, lambda_ce=0.5),\n",
    "        FocalLoss(gamma=2.0, weight=torch.tensor([1.0, 2.0, 3.0], device=device))  # Higher weight for tumor classes\n",
    "    ]\n",
    "    loss_weights = [0.7, 0.3]  # Favor DiceCE over Focal\n",
    "\n",
    "    lr = 3e-4\n",
    "    max_epoch = 20\n",
    "    #out_dir = '/home/mailab/Documents/brats2023_updated/Result'\n",
    "    out_dir = 'D:/brats2023_updated/Result'\n",
    "\n",
    "    train(data_dir, model, loss_functions, loss_weights, lr, max_epoch, out_dir=out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "infer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T12:28:08.527029Z",
     "iopub.status.busy": "2025-07-12T12:28:08.526521Z",
     "iopub.status.idle": "2025-07-12T12:30:20.452316Z",
     "shell.execute_reply": "2025-07-12T12:30:20.451415Z",
     "shell.execute_reply.started": "2025-07-12T12:28:08.527005Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /kaggle/working/Result/backup_ckpts/epoch10.pth.tar...\n",
      "Model loaded.\n",
      "---------------------------------------------------\n",
      "TRAINING SUMMARY\n",
      "Model: UNet_3d (with 3,171,417 parameters)\n",
      "Loss functions: [DiceCELoss(\n",
      "  (dice): DiceLoss()\n",
      "  (cross_entropy): CrossEntropyLoss()\n",
      "  (binary_cross_entropy): BCEWithLogitsLoss()\n",
      "), FocalLoss()]\n",
      "Loss weights: [0.7, 0.3]\n",
      "Training regions: overlapping\n",
      "Epochs trained: 10\n",
      "Scheduler patience: 5\n",
      "---------------------------------------------------\n",
      "INFERENCE SUMMARY\n",
      "Data directory: /kaggle/input/validation/BraTS2024-SSA-Challenge-TestData\n",
      "Trained model checkpoint path: /kaggle/working/Result/backup_ckpts/epoch10.pth.tar\n",
      "Out directory: /kaggle/working/prediction\n",
      "Batch size: 1\n",
      "Postprocess function: <function rm_dust_fh at 0x7fd9540fa5c0>\n",
      "---------------------------------------------------\n",
      "Inference starts.\n",
      "Inference completed. Predictions saved in /kaggle/working/prediction/preds.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "#from ..utils.model_utils import make_dataloader\n",
    "#from ..utils.general_utils import probs_to_preds, save_pred_as_nifti\n",
    "\n",
    "\n",
    "def infer(data_dir, ckpt_path, out_dir=None, batch_size=1, postprocess_function=None):\n",
    "    \"\"\"Uses trained model to make predictions on test data.\n",
    "    Args:\n",
    "        data_dir: Directory of test data.\n",
    "        ckpt_path: Path of trained model.\n",
    "        out_dir: Directory in which to save predictions. Defaults to None.\n",
    "        batch_size: Batch size of dataloader. Defaults to 1.\n",
    "        postprocess_function: The postprocessing function to use. Defaults to None.\n",
    "    \"\"\"\n",
    "    # Set up directories and paths.\n",
    "    if out_dir is None:\n",
    "        out_dir = os.getcwd()\n",
    "    preds_dir = os.path.join(out_dir, 'preds')\n",
    "    if not os.path.exists(preds_dir):\n",
    "        os.makedirs(preds_dir)\n",
    "        os.system(f'chmod a+rwx {preds_dir}')\n",
    "    \n",
    "    print(f\"Loading model from {ckpt_path}...\")\n",
    "    checkpoint = torch.load(ckpt_path, weights_only=False)\n",
    "    model = checkpoint['model']\n",
    "    loss_functions = checkpoint['loss_functions']\n",
    "    loss_weights = checkpoint['loss_weights']\n",
    "    training_regions = checkpoint['training_regions']\n",
    "    epoch = checkpoint['epoch']\n",
    "    model_sd = checkpoint['model_sd']\n",
    "    \n",
    "    # Handle backward compatibility with older checkpoints\n",
    "    scheduler_patience = checkpoint.get('scheduler_patience', 'Not available (older checkpoint)')\n",
    "    \n",
    "    model.load_state_dict(model_sd)\n",
    "    print(f\"Model loaded.\")\n",
    "    \n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(f\"TRAINING SUMMARY\")\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Loss functions: {loss_functions}\") \n",
    "    print(f\"Loss weights: {loss_weights}\")\n",
    "    print(f\"Training regions: {training_regions}\")\n",
    "    print(f\"Epochs trained: {epoch}\")\n",
    "    print(f\"Scheduler patience: {scheduler_patience}\")\n",
    "    print(\"---------------------------------------------------\")\n",
    "    \n",
    "    print(\"INFERENCE SUMMARY\")\n",
    "    print(f\"Data directory: {data_dir}\")\n",
    "    print(f\"Trained model checkpoint path: {ckpt_path}\")\n",
    "    print(f\"Out directory: {out_dir}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Postprocess function: {postprocess_function}\")\n",
    "    print(\"---------------------------------------------------\")\n",
    "    \n",
    "    test_loader = make_dataloader(data_dir, shuffle=False, mode='test', augment=True, batch_size=batch_size)\n",
    "    \n",
    "    print('Inference starts.')\n",
    "    with torch.no_grad():\n",
    "        for subject_names, imgs in test_loader:\n",
    "            model.eval()\n",
    "            # Move data to GPU.\n",
    "            imgs = [img.cuda() for img in imgs] # img is B1HWD\n",
    "            x_in = torch.cat(imgs, dim=1) # x_in is B4HWD\n",
    "            \n",
    "            output = model(x_in)\n",
    "            if isinstance(output, dict):\n",
    "                output = output['final']\n",
    "            output = output.float()\n",
    "            \n",
    "            preds = probs_to_preds(output, training_regions)\n",
    "            # preds is B3HWD - each channel is one-hot encoding of a disjoint region\n",
    "            \n",
    "            # Iterate over batch and save each prediction.\n",
    "            for i, subject_name in enumerate(subject_names):\n",
    "                save_pred_as_nifti(preds[i], preds_dir, data_dir, subject_name, postprocess_function)\n",
    "    \n",
    "    print(f'Inference completed. Predictions saved in {preds_dir}.')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #from ..processing.postprocess import rm_dust_fh\n",
    "    \n",
    "    data_dir = '/kaggle/input/validation/BraTS2024-SSA-Challenge-TestData'\n",
    "    #ckpt_path = '/home/mailab/Documents/brats2023_updated/Result/latest_ckpt.pth.tar'\n",
    "    ckpt_path = '/kaggle/working/Result/backup_ckpts/epoch10.pth.tar'\n",
    "    out_dir = '/kaggle/working/prediction'\n",
    "    postprocess_function = rm_dust_fh\n",
    "    \n",
    "    infer(data_dir, ckpt_path, out_dir=out_dir, postprocess_function=postprocess_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tester.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T12:35:10.127104Z",
     "iopub.status.busy": "2025-07-12T12:35:10.126324Z",
     "iopub.status.idle": "2025-07-12T12:38:14.045416Z",
     "shell.execute_reply": "2025-07-12T12:38:14.044720Z",
     "shell.execute_reply.started": "2025-07-12T12:35:10.127065Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting BraTS 23 Africa Challenge Evaluation...\n",
      "Found 35 ground truth files\n",
      "Evaluating: BraTS-SSA-00158-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00134-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00169-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00132-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00138-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00154-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00218-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00180-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00155-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00139-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00136-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00163-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00130-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00198-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00226-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00140-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00143-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00157-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00137-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00129-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00225-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00126-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00171-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00227-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00179-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00188-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00125-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00228-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00192-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00148-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00206-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00210-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00175-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00174-000-seg.nii\n",
      "Evaluating: BraTS-SSA-00207-000-seg.nii\n",
      "Detailed results saved to brats23_africa_results.csv\n",
      "Summary statistics saved to brats23_africa_results_summary.csv\n",
      "\n",
      "=== EVALUATION SUMMARY ===\n",
      "Total cases evaluated: 35\n",
      "\n",
      "Mean scores:\n",
      "Dice_ET: 0.3968 Â± 0.2308\n",
      "Dice_TC: 0.4940 Â± 0.2788\n",
      "Dice_WT: 0.7430 Â± 0.2374\n",
      "Hausdorff95_ET: 24.9744 Â± 15.8041\n",
      "Hausdorff95_TC: 23.7815 Â± 16.1899\n",
      "Hausdorff95_WT: 17.6144 Â± 12.8773\n",
      "sensitivity: 0.7060 Â± 0.2308\n",
      "specificity: 0.9986 Â± 0.0011\n",
      "\n",
      "Lesion-wise metrics:\n",
      "LesionWise_Dice_ET: 0.7458 Â± 0.3174\n",
      "LesionWise_Dice_TC: 0.7789 Â± 0.3055\n",
      "LesionWise_Dice_WT: 0.5772 Â± 0.3014\n",
      "LesionWise_Hausdorff95_ET: 3.4746 Â± 4.3918\n",
      "LesionWise_Hausdorff95_TC: 4.0869 Â± 4.5677\n",
      "LesionWise_Hausdorff95_WT: 10.3627 Â± 5.1167\n",
      "Evaluation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# MONAI imports\n",
    "from monai.metrics import (\n",
    "    DiceMetric, \n",
    "    HausdorffDistanceMetric, \n",
    "    SurfaceDistanceMetric,\n",
    "    ConfusionMatrixMetric\n",
    ")\n",
    "from monai.transforms import (\n",
    "    Compose, \n",
    "    LoadImage, \n",
    "    EnsureChannelFirst, \n",
    "    ToTensor,\n",
    "    AsDiscrete\n",
    ")\n",
    "import torch\n",
    "\n",
    "class BraTSEvaluator:\n",
    "    def __init__(self, gt_folder, pred_folder):\n",
    "        \"\"\"\n",
    "        Initialize BraTS evaluator\n",
    "        \n",
    "        Args:\n",
    "            gt_folder (str): Path to ground truth folder\n",
    "            pred_folder (str): Path to predictions folder\n",
    "        \"\"\"\n",
    "        self.gt_folder = Path(gt_folder)\n",
    "        self.pred_folder = Path(pred_folder)\n",
    "        \n",
    "        # Initialize MONAI metrics\n",
    "        self.dice_metric = DiceMetric(include_background=False, reduction=\"mean_batch\")\n",
    "        self.hausdorff_metric = HausdorffDistanceMetric(include_background=False, percentile=95)\n",
    "        self.surface_distance_metric = SurfaceDistanceMetric(include_background=False)\n",
    "        self.confusion_matrix_metric = ConfusionMatrixMetric(include_background=False)\n",
    "        \n",
    "        # Transform for loading images\n",
    "        self.transform = Compose([\n",
    "            LoadImage(image_only=True),\n",
    "            EnsureChannelFirst(),\n",
    "            ToTensor()\n",
    "        ])\n",
    "        \n",
    "        # BraTS label mappings\n",
    "        self.label_mapping = {\n",
    "            'ET': 3,  # Enhancing Tumor\n",
    "            'TC': [1, 3],  # Tumor Core (ED + ET)\n",
    "            'WT': [1, 2, 3]  # Whole Tumor (ED + NET + ET)\n",
    "        }\n",
    "        \n",
    "        self.results = []\n",
    "    \n",
    "    def get_binary_mask(self, mask, labels):\n",
    "        mask = mask.int()\n",
    "        if isinstance(labels, int):\n",
    "            return (mask == labels).float()\n",
    "        else:\n",
    "            binary_mask = torch.zeros_like(mask, dtype=torch.bool)\n",
    "            for label in labels:\n",
    "                binary_mask = binary_mask | (mask == label)\n",
    "            return binary_mask.float()\n",
    "\n",
    "    def compute_lesion_wise_metrics(self, gt_mask, pred_mask, region):\n",
    "        \"\"\"Compute lesion-wise metrics\"\"\"\n",
    "        # Get connected components for ground truth\n",
    "        gt_np = gt_mask.cpu().numpy().astype(np.uint8)\n",
    "        pred_np = pred_mask.cpu().numpy().astype(np.uint8)\n",
    "        \n",
    "        # Simple connected components (you might want to use scipy.ndimage.label)\n",
    "        from scipy.ndimage import label as scipy_label\n",
    "        gt_labeled, num_gt_lesions = scipy_label(gt_np)\n",
    "        \n",
    "        if num_gt_lesions == 0:\n",
    "            return {\n",
    "                f'LesionWise_Dice_{region}': 0.0,\n",
    "                f'LesionWise_NSD_0.5_{region}': 0.0,\n",
    "                f'LesionWise_NSD_1.0_{region}': 0.0,\n",
    "                f'LesionWise_Hausdorff95_{region}': np.inf\n",
    "            }\n",
    "        \n",
    "        lesion_dices = []\n",
    "        lesion_nsd_05 = []\n",
    "        lesion_nsd_10 = []\n",
    "        lesion_hausdorff = []\n",
    "        \n",
    "        for lesion_id in range(1, num_gt_lesions + 1):\n",
    "            lesion_gt = (gt_labeled == lesion_id).astype(np.float32)\n",
    "            lesion_pred = pred_np * lesion_gt  # Prediction in lesion region\n",
    "            \n",
    "            # Convert back to torch tensors\n",
    "            lesion_gt_tensor = torch.from_numpy(lesion_gt).unsqueeze(0).unsqueeze(0)\n",
    "            lesion_pred_tensor = torch.from_numpy(lesion_pred).unsqueeze(0).unsqueeze(0)\n",
    "            \n",
    "            # Compute metrics for this lesion\n",
    "            if lesion_gt_tensor.sum() > 0:\n",
    "                # Dice\n",
    "                dice_val = self.dice_metric(lesion_pred_tensor, lesion_gt_tensor)\n",
    "                lesion_dices.append(dice_val.item())\n",
    "                \n",
    "                # Surface distance metrics\n",
    "                try:\n",
    "                    surface_distances = self.surface_distance_metric(lesion_pred_tensor, lesion_gt_tensor)\n",
    "                    nsd_05 = (surface_distances <= 0.5).float().mean()\n",
    "                    nsd_10 = (surface_distances <= 1.0).float().mean()\n",
    "                    lesion_nsd_05.append(nsd_05.item())\n",
    "                    lesion_nsd_10.append(nsd_10.item())\n",
    "                except:\n",
    "                    lesion_nsd_05.append(0.0)\n",
    "                    lesion_nsd_10.append(0.0)\n",
    "                \n",
    "                # Hausdorff distance\n",
    "                try:\n",
    "                    hausdorff_val = self.hausdorff_metric(lesion_pred_tensor, lesion_gt_tensor)\n",
    "                    lesion_hausdorff.append(hausdorff_val.item())\n",
    "                except:\n",
    "                    lesion_hausdorff.append(np.inf)\n",
    "        \n",
    "        return {\n",
    "            f'LesionWise_Dice_{region}': np.mean(lesion_dices) if lesion_dices else 0.0,\n",
    "            f'LesionWise_NSD_0.5_{region}': np.mean(lesion_nsd_05) if lesion_nsd_05 else 0.0,\n",
    "            f'LesionWise_NSD_1.0_{region}': np.mean(lesion_nsd_10) if lesion_nsd_10 else 0.0,\n",
    "            f'LesionWise_Hausdorff95_{region}': np.mean(lesion_hausdorff) if lesion_hausdorff else np.inf\n",
    "        }\n",
    "    \n",
    "    def compute_sensitivity_specificity(self, gt_mask, pred_mask):\n",
    "        \"\"\"Compute sensitivity and specificity\"\"\"\n",
    "        # Flatten masks\n",
    "        gt_flat = gt_mask.flatten()\n",
    "        pred_flat = pred_mask.flatten()\n",
    "        \n",
    "        # Convert to binary (any tumor vs background)\n",
    "        gt_binary = (gt_flat > 0).float()\n",
    "        pred_binary = (pred_flat > 0).float()\n",
    "        \n",
    "        # Compute confusion matrix components\n",
    "        tp = ((gt_binary == 1) & (pred_binary == 1)).sum().item()\n",
    "        tn = ((gt_binary == 0) & (pred_binary == 0)).sum().item()\n",
    "        fp = ((gt_binary == 0) & (pred_binary == 1)).sum().item()\n",
    "        fn = ((gt_binary == 1) & (pred_binary == 0)).sum().item()\n",
    "        \n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "        \n",
    "        return sensitivity, specificity\n",
    "    \n",
    "    def evaluate_case(self, gt_file, pred_file):\n",
    "        \"\"\"Evaluate a single case\"\"\"\n",
    "        print(f\"Evaluating: {gt_file.name}\")\n",
    "        \n",
    "        # Load images\n",
    "        gt_img = self.transform(gt_file)\n",
    "        pred_img = self.transform(pred_file)\n",
    "        \n",
    "        # Ensure same shape and add batch dimension\n",
    "        if gt_img.shape != pred_img.shape:\n",
    "            print(f\"Warning: Shape mismatch for {gt_file.name}\")\n",
    "            return None\n",
    "        \n",
    "        gt_img = gt_img.unsqueeze(0)  # Add batch dimension\n",
    "        pred_img = pred_img.unsqueeze(0)\n",
    "        \n",
    "        case_results = {'case_id': gt_file.stem}\n",
    "        \n",
    "        # Evaluate each region (ET, TC, WT)\n",
    "        for region, labels in self.label_mapping.items():\n",
    "            # Get binary masks for current region\n",
    "            gt_region = self.get_binary_mask(gt_img, labels)\n",
    "            pred_region = self.get_binary_mask(pred_img, labels)\n",
    "            \n",
    "            # Standard metrics\n",
    "            try:\n",
    "                # Dice\n",
    "                dice_val = self.dice_metric(pred_region, gt_region)\n",
    "                case_results[f'Dice_{region}'] = dice_val.item()\n",
    "                \n",
    "                # Hausdorff Distance\n",
    "                hausdorff_val = self.hausdorff_metric(pred_region, gt_region)\n",
    "                case_results[f'Hausdorff95_{region}'] = hausdorff_val.item()\n",
    "                \n",
    "                # Surface Distance (NSD)\n",
    "                surface_distances = self.surface_distance_metric(pred_region, gt_region)\n",
    "                nsd_05 = (surface_distances <= 0.5).float().mean()\n",
    "                nsd_10 = (surface_distances <= 1.0).float().mean()\n",
    "                case_results[f'NSD_0.5_{region}'] = nsd_05.item()\n",
    "                case_results[f'NSD_1.0_{region}'] = nsd_10.item()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error computing standard metrics for {region}: {e}\")\n",
    "                case_results[f'Dice_{region}'] = 0.0\n",
    "                case_results[f'Hausdorff95_{region}'] = np.inf\n",
    "                case_results[f'NSD_0.5_{region}'] = 0.0\n",
    "                case_results[f'NSD_1.0_{region}'] = 0.0\n",
    "            \n",
    "            # Lesion-wise metrics\n",
    "            try:\n",
    "                lesion_metrics = self.compute_lesion_wise_metrics(gt_region.squeeze(), pred_region.squeeze(), region)\n",
    "                case_results.update(lesion_metrics)\n",
    "            except Exception as e:\n",
    "                print(f\"Error computing lesion-wise metrics for {region}: {e}\")\n",
    "                case_results[f'LesionWise_Dice_{region}'] = 0.0\n",
    "                case_results[f'LesionWise_NSD_0.5_{region}'] = 0.0\n",
    "                case_results[f'LesionWise_NSD_1.0_{region}'] = 0.0\n",
    "                case_results[f'LesionWise_Hausdorff95_{region}'] = np.inf\n",
    "        \n",
    "        # Sensitivity and Specificity (overall)\n",
    "        try:\n",
    "            sensitivity, specificity = self.compute_sensitivity_specificity(gt_img.squeeze(), pred_img.squeeze())\n",
    "            case_results['sensitivity'] = sensitivity\n",
    "            case_results['specificity'] = specificity\n",
    "        except Exception as e:\n",
    "            print(f\"Error computing sensitivity/specificity: {e}\")\n",
    "            case_results['sensitivity'] = 0.0\n",
    "            case_results['specificity'] = 0.0\n",
    "        \n",
    "        return case_results\n",
    "    \n",
    "    def run_evaluation(self):\n",
    "        \"\"\"Run evaluation on all cases\"\"\"\n",
    "        # Get all ground truth files\n",
    "        gt_files = list(self.gt_folder.glob('*.nii.gz'))\n",
    "        if not gt_files:\n",
    "            gt_files = list(self.gt_folder.glob('*.nii'))\n",
    "        \n",
    "        print(f\"Found {len(gt_files)} ground truth files\")\n",
    "        \n",
    "        for gt_file in gt_files:\n",
    "            # Find corresponding prediction file\n",
    "            pred_file = self.pred_folder / gt_file.name\n",
    "            if not pred_file.exists():\n",
    "                # Try different naming conventions\n",
    "                possible_names = [\n",
    "                    gt_file.name,\n",
    "                    gt_file.name.replace('_seg', ''),\n",
    "                    gt_file.name.replace('_gt', ''),\n",
    "                    gt_file.stem + '_pred.nii.gz'\n",
    "                ]\n",
    "                \n",
    "                for name in possible_names:\n",
    "                    pred_file = self.pred_folder / name\n",
    "                    if pred_file.exists():\n",
    "                        break\n",
    "                \n",
    "                if not pred_file.exists():\n",
    "                    print(f\"Prediction file not found for {gt_file.name}\")\n",
    "                    continue\n",
    "            \n",
    "            # Evaluate case\n",
    "            case_result = self.evaluate_case(gt_file, pred_file)\n",
    "            if case_result:\n",
    "                self.results.append(case_result)\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def save_results(self, output_file='brats_evaluation_results.csv'):\n",
    "        \"\"\"Save evaluation results to CSV\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"No results to save\")\n",
    "            return\n",
    "        \n",
    "        df = pd.DataFrame(self.results)\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        summary_stats = df[numeric_cols].agg(['mean', 'std', 'median', 'min', 'max'])\n",
    "        \n",
    "        # Save detailed results\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Detailed results saved to {output_file}\")\n",
    "        \n",
    "        # Save summary statistics\n",
    "        summary_file = output_file.replace('.csv', '_summary.csv')\n",
    "        summary_stats.to_csv(summary_file)\n",
    "        print(f\"Summary statistics saved to {summary_file}\")\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n=== EVALUATION SUMMARY ===\")\n",
    "        print(f\"Total cases evaluated: {len(df)}\")\n",
    "        print(\"\\nMean scores:\")\n",
    "        \n",
    "        # Standard metrics\n",
    "        for col in ['Dice_ET', 'Dice_TC', 'Dice_WT', \n",
    "                   'Hausdorff95_ET', 'Hausdorff95_TC', 'Hausdorff95_WT',\n",
    "                   'sensitivity', 'specificity']:\n",
    "            if col in df.columns:\n",
    "                print(f\"{col}: {df[col].mean():.4f} Â± {df[col].std():.4f}\")\n",
    "        \n",
    "        # Lesion-wise metrics\n",
    "        print(\"\\nLesion-wise metrics:\")\n",
    "        for col in ['LesionWise_Dice_ET', 'LesionWise_Dice_TC', 'LesionWise_Dice_WT',\n",
    "                   'LesionWise_Hausdorff95_ET', 'LesionWise_Hausdorff95_TC', 'LesionWise_Hausdorff95_WT']:\n",
    "            if col in df.columns:\n",
    "                print(f\"{col}: {df[col].mean():.4f} Â± {df[col].std():.4f}\")\n",
    "        \n",
    "        return df, summary_stats\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run BraTS evaluation\"\"\"\n",
    "    # Set your folder paths here\n",
    "    gt_folder = \"/kaggle/input/original-validation/original validation\"\n",
    "    pred_folder = \"prediction/preds\"\n",
    "    \n",
    "    # Initialize evaluator\n",
    "    evaluator = BraTSEvaluator(gt_folder, pred_folder)\n",
    "    \n",
    "    # Run evaluation\n",
    "    print(\"Starting BraTS 23 Africa Challenge Evaluation...\")\n",
    "    results = evaluator.run_evaluation()\n",
    "    \n",
    "    if results:\n",
    "        # Save results\n",
    "        df, summary = evaluator.save_results('brats23_africa_results.csv')\n",
    "        print(\"Evaluation completed successfully!\")\n",
    "    else:\n",
    "        print(\"No valid results found. Please check your file paths and formats.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T12:26:26.944348Z",
     "iopub.status.busy": "2025-07-12T12:26:26.944061Z",
     "iopub.status.idle": "2025-07-12T12:26:26.986935Z",
     "shell.execute_reply": "2025-07-12T12:26:26.986039Z",
     "shell.execute_reply.started": "2025-07-12T12:26:26.944328Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: '/kaggle/input/brats-africa-dataset/BraTS-Africa Dataset/BraTS-Africa/95_Glioma/BraTS-SSA-00125-000'-t1c.nii'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: \"/kaggle/input/brats-africa-dataset/BraTS-Africa Dataset/BraTS-Africa/95_Glioma/BraTS-SSA-00125-000'-t1c.nii\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_117/900775591.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0msubject_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"BraTS-SSA-00125-000'\"\u001b[0m  \u001b[0;31m# Replace with actual subject ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0mvisualize_gt_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_117/900775591.py\u001b[0m in \u001b[0;36mvisualize_gt_pred\u001b[0;34m(data_dir, subject_name, gt_dir, pred_dir, slice_index)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Load full brain MRI (assumed t1ce modality for example)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{subject_name}-t1c.nii\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mimg_nii\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_nii\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No such file or no access: '{filename}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstat_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImageFileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Empty file: '{filename}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: '/kaggle/input/brats-africa-dataset/BraTS-Africa Dataset/BraTS-Africa/95_Glioma/BraTS-SSA-00125-000'-t1c.nii'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def overlay_mask_on_image(image, mask, color, alpha=0.4):\n",
    "    \"\"\"Return an RGB image with the mask overlaid in color.\"\"\"\n",
    "    img_rgb = np.stack([image]*3, axis=-1)\n",
    "    colored_mask = np.zeros_like(img_rgb)\n",
    "    for i in range(3):\n",
    "        colored_mask[..., i] = color[i]\n",
    "    # Normalize image to 0-1 for display\n",
    "    img_norm = (image - image.min()) / (image.max() - image.min())\n",
    "    img_rgb = np.stack([img_norm]*3, axis=-1)\n",
    "    overlay = img_rgb.copy()\n",
    "    overlay[mask > 0] = (1 - alpha) * img_rgb[mask > 0] + alpha * colored_mask[mask > 0]\n",
    "    return overlay\n",
    "\n",
    "def visualize_gt_pred(data_dir, subject_name, gt_dir, pred_dir, slice_index=None):\n",
    "    \"\"\"\n",
    "    Visualize ground truth and prediction overlays for a subject.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: path to full brain MRI files (assumed nifti)\n",
    "        subject_name: subject identifier (filename prefix)\n",
    "        gt_dir: path to ground truth masks (nifti)\n",
    "        pred_dir: path to predicted masks (nifti)\n",
    "        slice_index: axial slice index to visualize (if None, use middle slice)\n",
    "    \"\"\"\n",
    "    # Load full brain MRI (assumed t1ce modality for example)\n",
    "    img_path = os.path.join(data_dir, f\"{subject_name}-t1c.nii\") \n",
    "    img_nii = nib.load(img_path)\n",
    "    img = img_nii.get_fdata()\n",
    "    \n",
    "    # Load ground truth segmentation\n",
    "    gt_path = os.path.join(gt_dir, f\"{subject_name}-seg.nii\") \n",
    "    gt_nii = nib.load(gt_path)\n",
    "    gt = gt_nii.get_fdata()\n",
    "    \n",
    "    # Load prediction segmentation\n",
    "    pred_path = os.path.join(pred_dir, f\"{subject_name}-seg.nii\") \n",
    "    pred_nii = nib.load(pred_path)\n",
    "    pred = pred_nii.get_fdata()\n",
    "    \n",
    "    # Choose slice\n",
    "    if slice_index is None:\n",
    "        slice_index = img.shape[2] // 2\n",
    "    \n",
    "    img_slice = img[:, :, slice_index]\n",
    "    gt_slice = gt[:, :, slice_index]\n",
    "    pred_slice = pred[:, :, slice_index]\n",
    "    \n",
    "    # Define subregions masks for GT and pred\n",
    "    def get_subregion_masks(seg):\n",
    "        ET_mask = (seg == 3)\n",
    "        TC_mask = np.isin(seg, [1,3])\n",
    "        WT_mask = np.isin(seg, [1,2,3])\n",
    "        return ET_mask, TC_mask, WT_mask\n",
    "    \n",
    "    gt_ET, gt_TC, gt_WT = get_subregion_masks(gt_slice)\n",
    "    pred_ET, pred_TC, pred_WT = get_subregion_masks(pred_slice)\n",
    "    \n",
    "    # Colors for overlays: ET-red, TC-yellow, WT-green\n",
    "    colors = {\n",
    "        'ET': [1, 0, 0],     # red\n",
    "        'TC': [1, 1, 0],     # yellow\n",
    "        'WT': [0, 1, 0],     # green\n",
    "    }\n",
    "    \n",
    "    # Create overlays\n",
    "    gt_overlay = overlay_mask_on_image(img_slice, gt_WT, colors['WT'], alpha=0.2)\n",
    "    gt_overlay = overlay_mask_on_image(gt_overlay, gt_TC, colors['TC'], alpha=0.3)\n",
    "    gt_overlay = overlay_mask_on_image(gt_overlay, gt_ET, colors['ET'], alpha=0.4)\n",
    "    \n",
    "    pred_overlay = overlay_mask_on_image(img_slice, pred_WT, colors['WT'], alpha=0.2)\n",
    "    pred_overlay = overlay_mask_on_image(pred_overlay, pred_TC, colors['TC'], alpha=0.3)\n",
    "    pred_overlay = overlay_mask_on_image(pred_overlay, pred_ET, colors['ET'], alpha=0.4)\n",
    "    \n",
    "    # Plot side by side\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axs[0].imshow(gt_overlay)\n",
    "    axs[0].set_title(f\"{subject_name} - Ground Truth\")\n",
    "    axs[1].imshow(pred_overlay)\n",
    "    axs[1].set_title(f\"{subject_name} - Prediction\")\n",
    "    \n",
    "    for ax in axs:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Legend patches\n",
    "    patches = [mpatches.Patch(color=colors[k], label=k) for k in ['ET', 'TC', 'WT']]\n",
    "    plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "data_dir = \"/kaggle/input/brats-africa-dataset/BraTS-Africa Dataset/BraTS-Africa/95_Glioma\"\n",
    "gt_dir = \"/kaggle/input/original-validation\"\n",
    "pred_dir = \"/kaggle/working/prediction/preds\"\n",
    "subject_name = \"BraTS-SSA-00125-000'\"  # Replace with actual subject ID\n",
    "\n",
    "visualize_gt_pred(data_dir, subject_name, gt_dir, pred_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6925204,
     "sourceId": 11108093,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7850912,
     "sourceId": 12446019,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7852655,
     "sourceId": 12448583,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
